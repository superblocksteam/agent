# =============================================================================
# Task Manager ScaledJob
#
# KEDA manages a pool of task-manager pods that:
# 1. Pull work from Redis queue
# 2. Dynamically create sandbox Jobs for execution
# 3. Communicate with sandbox via gRPC
# 4. Delete sandbox Jobs after execution
# 5. Self-terminate (ephemeral mode)
#
# Network isolation is enforced via Kubernetes NetworkPolicy on sandbox Jobs.
# Task-manager has full internal network access; sandbox Jobs are restricted.
# =============================================================================
{{- range $k, $v := .Values.ephemeral_worker.fleets }}
{{- $language := $v.language | required "language is required (python or javascript)" }}
{{- $sandboxConfig := index $.Values.ephemeral_worker.sandbox $language }}
{{- $podAnnotations := $v.podAnnotations | default $.Values.podAnnotations }}
---
apiVersion: keda.sh/v1alpha1
kind: ScaledJob
metadata:
  name: {{ $k }}
  labels:
    {{- include "ephemeral.worker.labels" $v | nindent 4 }}
spec:
  pollingInterval: {{ $v.keda.pollingInterval | default $.Values.ephemeral_worker.keda.pollingInterval }}
  successfulJobsHistoryLimit: {{ $v.keda.successfulJobsHistoryLimit | default $.Values.ephemeral_worker.keda.successfulJobsHistoryLimit }}
  failedJobsHistoryLimit: {{ $v.keda.failedJobsHistoryLimit | default $.Values.ephemeral_worker.keda.failedJobsHistoryLimit }}
  maxReplicaCount: {{ $v.keda.maxReplicaCount | default $.Values.ephemeral_worker.keda.maxReplicaCount }}
  minReplicaCount: {{ $v.keda.minReplicaCount | default $.Values.ephemeral_worker.keda.minReplicaCount }}
  {{- if or $v.keda.triggers $.Values.ephemeral_worker.keda.triggers }}
  triggers:
    {{- toYaml ($v.keda.triggers | default $.Values.ephemeral_worker.keda.triggers) | nindent 4 }}
  {{- else }}
  triggers:
    {{- range $v.triggerStreams }}
    - type: redis-streams
      metadata:
        host: {{ $.Values.ephemeral_worker.queue.host }}
        port: {{ $.Values.ephemeral_worker.queue.port | quote }}
        enableTLS: {{ $.Values.ephemeral_worker.queue.tls | quote }}
        stream: {{ . }}
        consumerGroup: {{ $v.consumerGroup }}
        activationLagCount: "1"
      authenticationRef:
        name: redis-trigger-auth
    {{- end }}
  {{- end }}
  scalingStrategy:
    {{- toYaml ($v.keda.scalingStrategy | default $.Values.ephemeral_worker.keda.scalingStrategy | default (dict "strategy" "accurate")) | nindent 4 }}
  jobTargetRef:
    parallelism: 1
    completions: 1
    backoffLimit: 0
    ttlSecondsAfterFinished: {{ $v.keda.ttlSecondsAfterFinished | default $.Values.ephemeral_worker.keda.ttlSecondsAfterFinished }}
    template:
      metadata:
        labels:
          {{- include "ephemeral.worker.labels" $v | nindent 10 }}
          role: task-manager
        {{- with $podAnnotations }}
        annotations:
          {{- toYaml . | nindent 10 }}
        {{- end }}
      spec:
        restartPolicy: Never
        terminationGracePeriodSeconds: 60
        serviceAccountName: task-manager
        {{- if $.Values.ephemeral_worker.image.credentials }}
        imagePullSecrets:
        - name: ephemeral-worker-docker
        {{- end }}

        containers:
        - name: task-manager
          image: "{{ (($v.taskManager).image).repository | default $.Values.ephemeral_worker.taskManager.image.repository }}:{{ (($v.taskManager).image).tag | default $.Values.ephemeral_worker.taskManager.image.tag }}"
          imagePullPolicy: {{ (($v.taskManager).image).pullPolicy | default $.Values.ephemeral_worker.taskManager.image.pullPolicy }}
          resources:
            {{- toYaml (deepCopy ($.Values.ephemeral_worker.taskManager.resources | default dict) | merge (($v.taskManager).resources | default dict)) | nindent 12 }}
          {{- if $.Values.ephemeral_worker.taskManager.probesEnabled }}
          {{- with (($v.taskManager).startupProbe) | default $.Values.ephemeral_worker.taskManager.startupProbe }}
          startupProbe:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          {{- with (($v.taskManager).readinessProbe) | default $.Values.ephemeral_worker.taskManager.readinessProbe }}
          readinessProbe:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          {{- with (($v.taskManager).livenessProbe) | default $.Values.ephemeral_worker.taskManager.livenessProbe }}
          livenessProbe:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          {{- end }}
          command: ["./task-manager"]
          args:
          # Ephemeral mode - process one job and exit
          {{- if $v.ephemeral }}
          - "--worker.ephemeral=true"
          {{- else if $.Values.ephemeral_worker.worker.ephemeral }}
          - "--worker.ephemeral=true"
          {{- else }}
          - "--worker.ephemeral=false"
          {{- end }}
          # Whether to use separate transport streams for sandboxed executions
          {{- if $v.useSeparateSandboxStreams }}
          - "--worker.sandbox.streams.separate=true"
          {{- else if $.Values.ephemeral_worker.worker.useSeparateSandboxStreams }}
          - "--worker.sandbox.streams.separate=true"
          {{- else }}
          - "--worker.sandbox.streams.separate=false"
          {{- end }}
          # Health check configuration
          - "--health.file={{ (($v.taskManager).healthFilePath) | default $.Values.ephemeral_worker.taskManager.healthFilePath }}"
          # Logging
          - "--log.level={{ $.Values.ephemeral_worker.observability.logging.level }}"
          # Sandbox mode - create separate sandbox Jobs
          - "--sandbox.namespace={{ $.Release.Namespace }}"
          - "--sandbox.image={{ (($v.sandbox).image).repository | default $sandboxConfig.image.repository }}:{{ (($v.sandbox).image).tag | default $sandboxConfig.image.tag }}"
          - "--sandbox.lang-executor.image={{ (($v.sandbox).langExecutorImage).repository | default $sandboxConfig.langExecutorImage.repository }}:{{ (($v.sandbox).langExecutorImage).tag | default $sandboxConfig.langExecutorImage.tag }}"
          - "--sandbox.port={{ $sandboxConfig.port | default $.Values.ephemeral_worker.sandbox.port }}"
          - "--sandbox.ttl={{ $.Values.ephemeral_worker.sandboxJob.ttlSecondsAfterFinished | default 60 }}"
          {{- if or $.Values.ephemeral_worker.sandbox.runtimeClassName $.Values.ephemeral_worker.runtimeClassName }}
          - "--sandbox.runtimeClass={{ $.Values.ephemeral_worker.sandbox.runtimeClassName | default $.Values.ephemeral_worker.runtimeClassName }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.image.credentials }}
          - "--sandbox.imagePullSecrets=ephemeral-worker-docker"
          {{- end }}
          {{- if or $.Values.nodeSelector $.Values.ephemeral_worker.sandbox.nodeSelector }}
          - "--sandbox.nodeSelector={{ include "mapToStringFlag" ($.Values.ephemeral_worker.sandbox.nodeSelector | default $.Values.ephemeral_worker.nodeSelector) }}"
          {{- end }}
          {{- range ($.Values.ephemeral_worker.sandbox.tolerations | default $.Values.ephemeral_worker.tolerations) }}
          - "--sandbox.toleration=key={{ .key }},operator={{ .operator }},value={{ .value }},effect={{ .effect }}"
          {{- end }}
          # gRPC configuration (variable store for sandbox)
          - "--variable.store.grpc.port={{ $.Values.ephemeral_worker.grpc.port }}"
          # Worker configuration
          - "--worker.consumer.group={{ $v.consumerGroup }}"
          {{- if $v.plugins }}
          - "--worker.plugins={{ join "," $v.plugins }}"
          {{- else if $.Values.ephemeral_worker.worker.plugins }}
          - "--worker.plugins={{ join "," $.Values.ephemeral_worker.worker.plugins }}"
          {{- end }}
          {{- if $v.events }}
          - "--worker.events={{ join "," $v.events }}"
          {{- else if $.Values.ephemeral_worker.worker.events }}
          - "--worker.events={{ join "," $.Values.ephemeral_worker.worker.events }}"
          {{- end }}
          {{- if $v.streams }}
          - "--worker.stream.keys={{ join "," $v.streams }}"
          {{- else if $.Values.ephemeral_worker.worker.streams }}
          - "--worker.stream.keys={{ join "," $.Values.ephemeral_worker.worker.streams }}"
          {{- else }}
          - "--worker.group={{ $.Values.ephemeral_worker.worker.group }}"
          {{- if $v.buckets }}
          - "--worker.buckets={{ join "," $v.buckets }}"
          {{- else if $.Values.ephemeral_worker.worker.buckets }}
          - "--worker.buckets={{ join "," $.Values.ephemeral_worker.worker.buckets }}"
          {{- end }}
          {{- end }}
          # Redis transport
          - "--transport.redis.host={{ $.Values.ephemeral_worker.queue.host }}"
          - "--transport.redis.port={{ $.Values.ephemeral_worker.queue.port }}"
          - "--transport.redis.tls={{ $.Values.ephemeral_worker.queue.tls }}"
          {{- if $.Values.ephemeral_worker.queue.servername }}
          - "--transport.redis.servername={{ $.Values.ephemeral_worker.queue.servername }}"
          {{- end }}
          - "--transport.redis.block.duration={{ $.Values.ephemeral_worker.queue.blockDuration }}"
          - "--transport.redis.max.messages={{ $.Values.ephemeral_worker.queue.batchSize }}"
          - "--transport.redis.execution.pool={{ $.Values.ephemeral_worker.queue.executionPool }}"
          - "--transport.redis.pool.max={{ $.Values.ephemeral_worker.queue.pool.max }}"
          - "--transport.redis.pool.min={{ $.Values.ephemeral_worker.queue.pool.min }}"
          {{- if $.Values.ephemeral_worker.queue.timeout.dial }}
          - "--transport.redis.timeout.dial={{ $.Values.ephemeral_worker.queue.timeout.dial }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.queue.timeout.read }}
          - "--transport.redis.timeout.read={{ $.Values.ephemeral_worker.queue.timeout.read }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.queue.timeout.write }}
          - "--transport.redis.timeout.write={{ $.Values.ephemeral_worker.queue.timeout.write }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.queue.timeout.pool }}
          - "--transport.redis.timeout.pool={{ $.Values.ephemeral_worker.queue.timeout.pool }}"
          {{- end }}
          # Redis store
          - "--store.redis.host={{ $.Values.ephemeral_worker.kvstore.host }}"
          - "--store.redis.port={{ $.Values.ephemeral_worker.kvstore.port }}"
          - "--store.redis.tls={{ $.Values.ephemeral_worker.kvstore.tls }}"
          {{- if $.Values.ephemeral_worker.kvstore.servername }}
          - "--store.redis.servername={{ $.Values.ephemeral_worker.kvstore.servername }}"
          {{- end }}
          - "--store.redis.pool.max={{ $.Values.ephemeral_worker.kvstore.pool.max }}"
          - "--store.redis.pool.min={{ $.Values.ephemeral_worker.kvstore.pool.min }}"
          {{- if $.Values.ephemeral_worker.kvstore.timeout.dial }}
          - "--store.redis.timeout.dial={{ $.Values.ephemeral_worker.kvstore.timeout.dial }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.kvstore.timeout.read }}
          - "--store.redis.timeout.read={{ $.Values.ephemeral_worker.kvstore.timeout.read }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.kvstore.timeout.write }}
          - "--store.redis.timeout.write={{ $.Values.ephemeral_worker.kvstore.timeout.write }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.kvstore.timeout.pool }}
          - "--store.redis.timeout.pool={{ $.Values.ephemeral_worker.kvstore.timeout.pool }}"
          {{- end }}
          # Observability
          {{- if $.Values.ephemeral_worker.observability.tracing.url }}
          - "--otel.collector.http.url={{ $.Values.ephemeral_worker.observability.tracing.url }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.observability.tracing.batchTimeout }}
          - "--otel.batcher.batch.timeout={{ $.Values.ephemeral_worker.observability.tracing.batchTimeout }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.observability.tracing.exportTimeout }}
          - "--otel.batcher.export.timeout={{ $.Values.ephemeral_worker.observability.tracing.exportTimeout }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.observability.tracing.maxExportBatchSize }}
          - "--otel.batcher.export.batch.max={{ $.Values.ephemeral_worker.observability.tracing.maxExportBatchSize }}"
          {{- end }}
          {{- if $.Values.ephemeral_worker.observability.tracing.maxQueueSize }}
          - "--otel.batcher.export.queue.max={{ $.Values.ephemeral_worker.observability.tracing.maxQueueSize }}"
          {{- end }}
          # Extra args from values
          {{- with $.Values.ephemeral_worker.taskManager.extraArgs }}
          {{- toYaml . | nindent 10 }}
          {{- end }}
          {{- with ($v.taskManager).extraArgs }}
          {{- toYaml . | nindent 10 }}
          {{- end }}
          env:
          # Pod info via Downward API
          # Required to properly set owner reference for sandbox cleanup
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: POD_UID
            valueFrom:
              fieldRef:
                fieldPath: metadata.uid
          - name: SUPERBLOCKS_WORKER_SANDBOX_TRANSPORT_REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                name: queue-redis-token
                key: token
          - name: SUPERBLOCKS_WORKER_SANDBOX_STORE_REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                name: kvstore-redis-token
                key: token
          - name: SUPERBLOCKS_WORKER_SANDBOX_SUPERBLOCKS_KEY
            valueFrom:
              secretKeyRef:
                name: dataplane-superblocks-key
                key: key
          {{- with ($v.taskManager).extraEnv }}
          {{- toYaml . | nindent 10 }}
          {{- end }}
          ports:
          - name: grpc
            containerPort: {{ $.Values.ephemeral_worker.grpc.port }}
            protocol: TCP

        {{- with $v.nodeSelector | default $.Values.ephemeral_worker.nodeSelector }}
        nodeSelector:
          {{- toYaml . | nindent 10 }}
        {{- end }}
        {{- with $v.affinity | default $.Values.ephemeral_worker.affinity }}
        affinity:
          {{- toYaml . | nindent 10 }}
        {{- end }}
        {{- with $v.tolerations | default $.Values.ephemeral_worker.tolerations }}
        tolerations:
          {{- toYaml . | nindent 10 }}
        {{- end }}
{{- end }}
