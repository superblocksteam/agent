// @generated by protoc-gen-es v1.2.0 with parameter "target=ts"
// @generated from file plugins/kafka/v1/plugin.proto (package plugins.kafka.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import type { BinaryReadOptions, FieldList, JsonReadOptions, JsonValue, PartialMessage, PlainMessage } from "@bufbuild/protobuf";
import { Message as Message$1, proto3, Value } from "@bufbuild/protobuf";
import { DynamicWorkflowConfiguration } from "../../common/v1/plugin_pb";

/**
 * @generated from enum plugins.kafka.v1.Operation
 */
export enum Operation {
  /**
   * @generated from enum value: OPERATION_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: OPERATION_CONSUME = 1;
   */
  CONSUME = 1,

  /**
   * @generated from enum value: OPERATION_PRODUCE = 2;
   */
  PRODUCE = 2,
}
// Retrieve enum metadata with: proto3.getEnumType(Operation)
proto3.util.setEnumType(Operation, "plugins.kafka.v1.Operation", [
  { no: 0, name: "OPERATION_UNSPECIFIED" },
  { no: 1, name: "OPERATION_CONSUME" },
  { no: 2, name: "OPERATION_PRODUCE" },
]);

/**
 * @generated from enum plugins.kafka.v1.Compression
 */
export enum Compression {
  /**
   * @generated from enum value: COMPRESSION_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: COMPRESSION_GZIP = 1;
   */
  GZIP = 1,

  /**
   * @generated from enum value: COMPRESSION_SNAPPY = 2;
   */
  SNAPPY = 2,

  /**
   * @generated from enum value: COMPRESSION_LZ4 = 3;
   */
  LZ4 = 3,

  /**
   * @generated from enum value: COMPRESSION_ZSTD = 4;
   */
  ZSTD = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(Compression)
proto3.util.setEnumType(Compression, "plugins.kafka.v1.Compression", [
  { no: 0, name: "COMPRESSION_UNSPECIFIED" },
  { no: 1, name: "COMPRESSION_GZIP" },
  { no: 2, name: "COMPRESSION_SNAPPY" },
  { no: 3, name: "COMPRESSION_LZ4" },
  { no: 4, name: "COMPRESSION_ZSTD" },
]);

/**
 * @generated from enum plugins.kafka.v1.Acks
 */
export enum Acks {
  /**
   * @generated from enum value: ACKS_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: ACKS_NONE = 1;
   */
  NONE = 1,

  /**
   * @generated from enum value: ACKS_LEADER = 2;
   */
  LEADER = 2,

  /**
   * @generated from enum value: ACKS_ALL = 3;
   */
  ALL = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(Acks)
proto3.util.setEnumType(Acks, "plugins.kafka.v1.Acks", [
  { no: 0, name: "ACKS_UNSPECIFIED" },
  { no: 1, name: "ACKS_NONE" },
  { no: 2, name: "ACKS_LEADER" },
  { no: 3, name: "ACKS_ALL" },
]);

/**
 * @generated from message plugins.kafka.v1.Metadata
 */
export class Metadata extends Message$1<Metadata> {
  /**
   * @generated from field: repeated plugins.kafka.v1.Topic topics = 1;
   */
  topics: Topic[] = [];

  /**
   * @generated from field: repeated plugins.kafka.v1.Broker brokers = 2;
   */
  brokers: Broker[] = [];

  constructor(data?: PartialMessage<Metadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Metadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "topics", kind: "message", T: Topic, repeated: true },
    { no: 2, name: "brokers", kind: "message", T: Broker, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Metadata {
    return new Metadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Metadata {
    return new Metadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Metadata {
    return new Metadata().fromJsonString(jsonString, options);
  }

  static equals(a: Metadata | PlainMessage<Metadata> | undefined, b: Metadata | PlainMessage<Metadata> | undefined): boolean {
    return proto3.util.equals(Metadata, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.Metadata.Minified
 */
export class Metadata_Minified extends Message$1<Metadata_Minified> {
  /**
   * @generated from field: repeated string topics = 1;
   */
  topics: string[] = [];

  constructor(data?: PartialMessage<Metadata_Minified>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Metadata.Minified";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "topics", kind: "scalar", T: 9 /* ScalarType.STRING */, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Metadata_Minified {
    return new Metadata_Minified().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Metadata_Minified {
    return new Metadata_Minified().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Metadata_Minified {
    return new Metadata_Minified().fromJsonString(jsonString, options);
  }

  static equals(a: Metadata_Minified | PlainMessage<Metadata_Minified> | undefined, b: Metadata_Minified | PlainMessage<Metadata_Minified> | undefined): boolean {
    return proto3.util.equals(Metadata_Minified, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.Broker
 */
export class Broker extends Message$1<Broker> {
  /**
   * @generated from field: int32 node_id = 1;
   */
  nodeId = 0;

  /**
   * @generated from field: string address = 2;
   */
  address = "";

  constructor(data?: PartialMessage<Broker>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Broker";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "node_id", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 2, name: "address", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Broker {
    return new Broker().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Broker {
    return new Broker().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Broker {
    return new Broker().fromJsonString(jsonString, options);
  }

  static equals(a: Broker | PlainMessage<Broker> | undefined, b: Broker | PlainMessage<Broker> | undefined): boolean {
    return proto3.util.equals(Broker, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.Topic
 */
export class Topic extends Message$1<Topic> {
  /**
   * @generated from field: string name = 1;
   */
  name = "";

  constructor(data?: PartialMessage<Topic>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Topic";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Topic {
    return new Topic().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Topic {
    return new Topic().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Topic {
    return new Topic().fromJsonString(jsonString, options);
  }

  static equals(a: Topic | PlainMessage<Topic> | undefined, b: Topic | PlainMessage<Topic> | undefined): boolean {
    return proto3.util.equals(Topic, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.Messages
 */
export class Messages extends Message$1<Messages> {
  /**
   * @generated from field: repeated plugins.kafka.v1.Message messages = 1;
   */
  messages: Message[] = [];

  constructor(data?: PartialMessage<Messages>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Messages";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "messages", kind: "message", T: Message, repeated: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Messages {
    return new Messages().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Messages {
    return new Messages().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Messages {
    return new Messages().fromJsonString(jsonString, options);
  }

  static equals(a: Messages | PlainMessage<Messages> | undefined, b: Messages | PlainMessage<Messages> | undefined): boolean {
    return proto3.util.equals(Messages, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.Message
 */
export class Message extends Message$1<Message> {
  /**
   * @generated from field: string topic = 1;
   */
  topic = "";

  /**
   * @generated from field: int32 partition = 2;
   */
  partition = 0;

  /**
   * @generated from field: int32 offset = 4;
   */
  offset = 0;

  /**
   * NOTE(frank): Need to use google.protobuf.Timestamp here but our json schema library doesn't support bigint.
   * Because of this, we can't use the google.protobuf.Timestamp type OR int64..... Since int32 isn't big enough
   * we have to use a string... // rant over.
   *
   * @generated from field: optional string timestamp = 3;
   */
  timestamp?: string;

  /**
   * @generated from field: optional google.protobuf.Value key = 5;
   */
  key?: Value;

  /**
   * @generated from field: optional google.protobuf.Value value = 6;
   */
  value?: Value;

  /**
   * NOTE(frank): We could use int64 but some Kafka clients (notably the one we're using) only supports int32.
   *
   * @generated from field: int32 length = 7;
   */
  length = 0;

  /**
   * NOTE(frank): Protobuf doesn't have an int8 type.
   *
   * @generated from field: int32 attributes = 8;
   */
  attributes = 0;

  /**
   * @generated from field: map<string, string> headers = 9;
   */
  headers: { [key: string]: string } = {};

  constructor(data?: PartialMessage<Message>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Message";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "topic", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "partition", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 4, name: "offset", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "timestamp", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 5, name: "key", kind: "message", T: Value, opt: true },
    { no: 6, name: "value", kind: "message", T: Value, opt: true },
    { no: 7, name: "length", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 8, name: "attributes", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 9, name: "headers", kind: "map", K: 9 /* ScalarType.STRING */, V: {kind: "scalar", T: 9 /* ScalarType.STRING */} },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Message {
    return new Message().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Message {
    return new Message().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Message {
    return new Message().fromJsonString(jsonString, options);
  }

  static equals(a: Message | PlainMessage<Message> | undefined, b: Message | PlainMessage<Message> | undefined): boolean {
    return proto3.util.equals(Message, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.SASL
 */
export class SASL extends Message$1<SASL> {
  /**
   * @generated from field: plugins.kafka.v1.SASL.Mechanism mechanism = 1;
   */
  mechanism = SASL_Mechanism.UNSPECIFIED;

  /**
   * non-aws fields
   *
   * @generated from field: optional string username = 2;
   */
  username?: string;

  /**
   * @generated from field: optional string password = 3;
   */
  password?: string;

  /**
   * aws fields
   *
   * @generated from field: optional string access_key_id = 4;
   */
  accessKeyId?: string;

  /**
   * @generated from field: optional string secret_key = 5;
   */
  secretKey?: string;

  /**
   * @generated from field: optional string session_token = 6;
   */
  sessionToken?: string;

  /**
   * @generated from field: optional string authorization_identity = 7;
   */
  authorizationIdentity?: string;

  constructor(data?: PartialMessage<SASL>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.SASL";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "mechanism", kind: "enum", T: proto3.getEnumType(SASL_Mechanism) },
    { no: 2, name: "username", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 3, name: "password", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 4, name: "access_key_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 5, name: "secret_key", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "session_token", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 7, name: "authorization_identity", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SASL {
    return new SASL().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SASL {
    return new SASL().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SASL {
    return new SASL().fromJsonString(jsonString, options);
  }

  static equals(a: SASL | PlainMessage<SASL> | undefined, b: SASL | PlainMessage<SASL> | undefined): boolean {
    return proto3.util.equals(SASL, a, b);
  }
}

/**
 * @generated from enum plugins.kafka.v1.SASL.Mechanism
 */
export enum SASL_Mechanism {
  /**
   * @generated from enum value: MECHANISM_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: MECHANISM_PLAIN = 1;
   */
  PLAIN = 1,

  /**
   * @generated from enum value: MECHANISM_SCRAM_SHA256 = 2;
   */
  SCRAM_SHA256 = 2,

  /**
   * @generated from enum value: MECHANISM_SCRAM_SHA512 = 3;
   */
  SCRAM_SHA512 = 3,

  /**
   * @generated from enum value: MECHANISM_AWS = 4;
   */
  AWS = 4,
}
// Retrieve enum metadata with: proto3.getEnumType(SASL_Mechanism)
proto3.util.setEnumType(SASL_Mechanism, "plugins.kafka.v1.SASL.Mechanism", [
  { no: 0, name: "MECHANISM_UNSPECIFIED" },
  { no: 1, name: "MECHANISM_PLAIN" },
  { no: 2, name: "MECHANISM_SCRAM_SHA256" },
  { no: 3, name: "MECHANISM_SCRAM_SHA512" },
  { no: 4, name: "MECHANISM_AWS" },
]);

/**
 * @generated from message plugins.kafka.v1.Cluster
 */
export class Cluster extends Message$1<Cluster> {
  /**
   * NOTE(frank): Due to limitations in our plugin template system, we can't use an array.....
   *
   * @generated from field: string brokers = 1;
   */
  brokers = "";

  /**
   * @generated from field: bool ssl = 2;
   */
  ssl = false;

  /**
   * @generated from field: plugins.kafka.v1.SASL sasl = 3;
   */
  sasl?: SASL;

  constructor(data?: PartialMessage<Cluster>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Cluster";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "brokers", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "ssl", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 3, name: "sasl", kind: "message", T: SASL },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Cluster {
    return new Cluster().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Cluster {
    return new Cluster().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Cluster {
    return new Cluster().fromJsonString(jsonString, options);
  }

  static equals(a: Cluster | PlainMessage<Cluster> | undefined, b: Cluster | PlainMessage<Cluster> | undefined): boolean {
    return proto3.util.equals(Cluster, a, b);
  }
}

/**
 * NOTE(frank): Since it's Kafka, there's a zillion options. We'll start with the basics for now.
 *
 * @generated from message plugins.kafka.v1.Plugin
 */
export class Plugin extends Message$1<Plugin> {
  /**
   * @generated from field: optional string name = 1;
   */
  name?: string;

  /**
   * @generated from field: plugins.kafka.v1.Operation operation = 2;
   */
  operation = Operation.UNSPECIFIED;

  /**
   * @generated from field: plugins.kafka.v1.Plugin.Produce produce = 3;
   */
  produce?: Plugin_Produce;

  /**
   * @generated from field: plugins.kafka.v1.Plugin.Consume consume = 4;
   */
  consume?: Plugin_Consume;

  /**
   * @generated from field: plugins.kafka.v1.Cluster cluster = 5;
   */
  cluster?: Cluster;

  /**
   * DEPRECATED
   *
   * @generated from field: plugins.kafka.v1.SuperblocksMetadata superblocksMetadata = 6;
   */
  superblocksMetadata?: SuperblocksMetadata;

  /**
   * @generated from field: optional plugins.common.v1.DynamicWorkflowConfiguration dynamic_workflow_configuration = 7;
   */
  dynamicWorkflowConfiguration?: DynamicWorkflowConfiguration;

  constructor(data?: PartialMessage<Plugin>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Plugin";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 2, name: "operation", kind: "enum", T: proto3.getEnumType(Operation) },
    { no: 3, name: "produce", kind: "message", T: Plugin_Produce },
    { no: 4, name: "consume", kind: "message", T: Plugin_Consume },
    { no: 5, name: "cluster", kind: "message", T: Cluster },
    { no: 6, name: "superblocksMetadata", kind: "message", T: SuperblocksMetadata },
    { no: 7, name: "dynamic_workflow_configuration", kind: "message", T: DynamicWorkflowConfiguration, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Plugin {
    return new Plugin().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Plugin {
    return new Plugin().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Plugin {
    return new Plugin().fromJsonString(jsonString, options);
  }

  static equals(a: Plugin | PlainMessage<Plugin> | undefined, b: Plugin | PlainMessage<Plugin> | undefined): boolean {
    return proto3.util.equals(Plugin, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.Plugin.Consume
 */
export class Plugin_Consume extends Message$1<Plugin_Consume> {
  /**
   * @generated from field: plugins.kafka.v1.Plugin.Consume.From from = 1;
   */
  from = Plugin_Consume_From.UNSPECIFIED;

  /**
   * NOTE(frank): SMH. Because our form template system if VERY limited,
   * there no way to send an array to the backend if we take in one topic in the UI.
   *
   * @generated from field: string topic = 2;
   */
  topic = "";

  /**
   * @generated from field: optional string group_id = 3;
   */
  groupId?: string;

  /**
   * @generated from field: optional string client_id = 4;
   */
  clientId?: string;

  /**
   * NOTE(frank): Another instance of template system limitations...
   *
   * @generated from field: plugins.kafka.v1.Plugin.Consume.Seek seek = 5;
   */
  seek?: Plugin_Consume_Seek;

  /**
   * @generated from field: bool read_uncommitted = 6;
   */
  readUncommitted = false;

  constructor(data?: PartialMessage<Plugin_Consume>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Plugin.Consume";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "from", kind: "enum", T: proto3.getEnumType(Plugin_Consume_From) },
    { no: 2, name: "topic", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 3, name: "group_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 4, name: "client_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 5, name: "seek", kind: "message", T: Plugin_Consume_Seek },
    { no: 6, name: "read_uncommitted", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Plugin_Consume {
    return new Plugin_Consume().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Plugin_Consume {
    return new Plugin_Consume().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Plugin_Consume {
    return new Plugin_Consume().fromJsonString(jsonString, options);
  }

  static equals(a: Plugin_Consume | PlainMessage<Plugin_Consume> | undefined, b: Plugin_Consume | PlainMessage<Plugin_Consume> | undefined): boolean {
    return proto3.util.equals(Plugin_Consume, a, b);
  }
}

/**
 * @generated from enum plugins.kafka.v1.Plugin.Consume.From
 */
export enum Plugin_Consume_From {
  /**
   * @generated from enum value: FROM_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: FROM_BEGINNING = 1;
   */
  BEGINNING = 1,

  /**
   * @generated from enum value: FROM_LATEST = 2;
   */
  LATEST = 2,

  /**
   * @generated from enum value: FROM_SEEK = 3;
   */
  SEEK = 3,
}
// Retrieve enum metadata with: proto3.getEnumType(Plugin_Consume_From)
proto3.util.setEnumType(Plugin_Consume_From, "plugins.kafka.v1.Plugin.Consume.From", [
  { no: 0, name: "FROM_UNSPECIFIED" },
  { no: 1, name: "FROM_BEGINNING" },
  { no: 2, name: "FROM_LATEST" },
  { no: 3, name: "FROM_SEEK" },
]);

/**
 * @generated from message plugins.kafka.v1.Plugin.Consume.Seek
 */
export class Plugin_Consume_Seek extends Message$1<Plugin_Consume_Seek> {
  /**
   * @generated from field: string topic = 1;
   */
  topic = "";

  /**
   * @generated from field: int32 offset = 2;
   */
  offset = 0;

  /**
   * @generated from field: int32 partition = 3;
   */
  partition = 0;

  constructor(data?: PartialMessage<Plugin_Consume_Seek>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Plugin.Consume.Seek";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "topic", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "offset", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
    { no: 3, name: "partition", kind: "scalar", T: 5 /* ScalarType.INT32 */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Plugin_Consume_Seek {
    return new Plugin_Consume_Seek().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Plugin_Consume_Seek {
    return new Plugin_Consume_Seek().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Plugin_Consume_Seek {
    return new Plugin_Consume_Seek().fromJsonString(jsonString, options);
  }

  static equals(a: Plugin_Consume_Seek | PlainMessage<Plugin_Consume_Seek> | undefined, b: Plugin_Consume_Seek | PlainMessage<Plugin_Consume_Seek> | undefined): boolean {
    return proto3.util.equals(Plugin_Consume_Seek, a, b);
  }
}

/**
 * @generated from message plugins.kafka.v1.Plugin.Produce
 */
export class Plugin_Produce extends Message$1<Plugin_Produce> {
  /**
   * @generated from field: plugins.kafka.v1.Acks acks = 1;
   */
  acks = Acks.UNSPECIFIED;

  /**
   * @generated from field: optional string client_id = 2;
   */
  clientId?: string;

  /**
   * @generated from field: optional int32 timeout = 3;
   */
  timeout?: number;

  /**
   * @generated from field: optional plugins.kafka.v1.Compression compression = 4;
   */
  compression?: Compression;

  /**
   * @generated from field: optional string transaction_id = 5;
   */
  transactionId?: string;

  /**
   * @generated from field: bool auto_create_topic = 6;
   */
  autoCreateTopic = false;

  /**
   * @generated from field: bool idempotent = 7;
   */
  idempotent = false;

  /**
   * @generated from field: bool transaction = 8;
   */
  transaction = false;

  /**
   * @generated from field: string messages = 9;
   */
  messages = "";

  constructor(data?: PartialMessage<Plugin_Produce>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.Plugin.Produce";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "acks", kind: "enum", T: proto3.getEnumType(Acks) },
    { no: 2, name: "client_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 3, name: "timeout", kind: "scalar", T: 5 /* ScalarType.INT32 */, opt: true },
    { no: 4, name: "compression", kind: "enum", T: proto3.getEnumType(Compression), opt: true },
    { no: 5, name: "transaction_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 6, name: "auto_create_topic", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 7, name: "idempotent", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 8, name: "transaction", kind: "scalar", T: 8 /* ScalarType.BOOL */ },
    { no: 9, name: "messages", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): Plugin_Produce {
    return new Plugin_Produce().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): Plugin_Produce {
    return new Plugin_Produce().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): Plugin_Produce {
    return new Plugin_Produce().fromJsonString(jsonString, options);
  }

  static equals(a: Plugin_Produce | PlainMessage<Plugin_Produce> | undefined, b: Plugin_Produce | PlainMessage<Plugin_Produce> | undefined): boolean {
    return proto3.util.equals(Plugin_Produce, a, b);
  }
}

/**
 * DEPRECATED
 *
 * @generated from message plugins.kafka.v1.SuperblocksMetadata
 */
export class SuperblocksMetadata extends Message$1<SuperblocksMetadata> {
  /**
   * @generated from field: optional string plugin_version = 1;
   */
  pluginVersion?: string;

  /**
   * @generated from field: optional string synced_from_profile_id = 2;
   */
  syncedFromProfileId?: string;

  constructor(data?: PartialMessage<SuperblocksMetadata>) {
    super();
    proto3.util.initPartial(data, this);
  }

  static readonly runtime: typeof proto3 = proto3;
  static readonly typeName = "plugins.kafka.v1.SuperblocksMetadata";
  static readonly fields: FieldList = proto3.util.newFieldList(() => [
    { no: 1, name: "plugin_version", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
    { no: 2, name: "synced_from_profile_id", kind: "scalar", T: 9 /* ScalarType.STRING */, opt: true },
  ]);

  static fromBinary(bytes: Uint8Array, options?: Partial<BinaryReadOptions>): SuperblocksMetadata {
    return new SuperblocksMetadata().fromBinary(bytes, options);
  }

  static fromJson(jsonValue: JsonValue, options?: Partial<JsonReadOptions>): SuperblocksMetadata {
    return new SuperblocksMetadata().fromJson(jsonValue, options);
  }

  static fromJsonString(jsonString: string, options?: Partial<JsonReadOptions>): SuperblocksMetadata {
    return new SuperblocksMetadata().fromJsonString(jsonString, options);
  }

  static equals(a: SuperblocksMetadata | PlainMessage<SuperblocksMetadata> | undefined, b: SuperblocksMetadata | PlainMessage<SuperblocksMetadata> | undefined): boolean {
    return proto3.util.equals(SuperblocksMetadata, a, b);
  }
}

